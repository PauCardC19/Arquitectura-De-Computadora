<!DOCTYPE HTML>
<html>
			<head>
			  <meta charset = "utf-8">
			  <meta name="viewport" content="width=device-width, initial-scale=2">
			<title>Temario</title>
			<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.2.0-beta1/dist/css/bootstrap.min.css" rel="stylesheet" 
			integrity="sha384-0evHe/X+R7YkIZDRvuzKMRqM+OrBnVFBL6DOitfPri4tjfHxaWutUpFmBp4vmVor" crossorigin="anonymous">
				<style>
			#myBtn {
		  display: none; /* Hidden by default */
		  position: fixed; /* Fixed/sticky position */
		  bottom: 20px; /* Place the button at the bottom of the page */
		  right: 30px; /* Place the button 30px from the right */
		  z-index: 99; /* Make sure it does not overlap */
		  border: none; /* Remove borders */
		  outline: none; /* Remove outline */
		  background-color: #20B2AA; /* Set a background color */
		  color: white; /* Text color */
		  cursor: pointer; /* Add a mouse pointer on hover */
		  padding: 15px; /* Some padding */
		  border-radius: 10px; /* Rounded corners */
		  font-size: 18px; /* Increase font size */
		}

		#myBtn:hover {
		  background-color: #555; /* Add a dark-grey background on hover */
		}
		</style>
			</head>
				<body bgcolor="azure" background =  "Imagenes/fondo.jpg"    text="black">
				<h1 align="center" style = "color:limegreen">Arquitectura de computadoras</h1>
				<h4  style="text-align:justify;font-weight:bold; font-family:Lucida Bright;text-align:right; color:#E74C3C ">Cardenas Casta√±uela Paulina</h4>
				
				<!-- imagen del tec -->
			<div style="width:50%"> <img src = "IMAGENES/imagenTec.png" style="height:170px; width:150px; float: left padding:0; margin:0"> </div>
			<!-- icono -->
			<a href="https://saltillo.tecnm.mx/">
			<img src="IMAGENES/TECNM.jpeg" width="80" height="45" align="right"></a>
			<!--BOTON -->	
	<button onclick="topFunction()" id="myBtn" title="Go to top">Back To Top</button>

			<script>
			// Get the button
			let mybutton = document.getElementById("myBtn");

			// When the user scrolls down 20px from the top of the document, show the button
			window.onscroll = function() {scrollFunction()};

			function scrollFunction() {
			  if (document.body.scrollTop > 20 || document.documentElement.scrollTop > 20) {
				mybutton.style.display = "block";
			  } else {
				mybutton.style.display = "none";
			  }
			}

			// When the user clicks on the button, scroll to the top of the document
			function topFunction() {
			  document.body.scrollTop = 0;
			  document.documentElement.scrollTop = 0;
			}
</script>

	<!--FIN BOTON---->
		  <style> 
		  body{background-color:white; padding:10px; font-family:Arial;}
		  
		  #menu{
				background-color:#952F57;
		  }
		  #menu ul{
				list-style: none;
				margin:0;
				padding:5;
		  }
		  #menu ul li{
				display: inline-block;
		  }
		  #menu ul li a{
				color: white;
				text-decoration:none;
				display:block;
				padding:10px;
				}
		  #menu ul li a:hover{
				background-color:#800040;
		  }
		  </style>
		 <div id="menu">
		  <ul>
		  <li class="active"><a href="Inicio.html">INICIO</a></li>
		   <li class="active"><a href="Unidad1.html">UNIDAD 1</a></li>
		  <li class="active"><a href="Unidad2.html">UNIDAD 2</a></li>
		  <li class="active"><a href="Unidad3.html">UNIDAD 3</a></li>
		  <li class="active"><a href="Unidad4.html">UNIDAD 4</a></li>
		   <li class="active"><a href="PRACTICAS.html">PRACTICAS</a></li>
		  </ul>
		  </div>
		  
		  <!-- LISTA DE TEMAS DE LA UNIDAD 4 -->
		   <div class = "container text-center mt-2">
		  <h3 class="display-10" align="right"> Unidad 4|  Procesamiento paralelo</h3>
		  <br></br>
				
		<!-- LISTA DE TEMAS DE LA UNIDAD 4 -->
				<h4 align= "Left "><li> <a href = "#4.1 Aspectos b√°sicos de la computaci√≥n paralela">4.1 Aspectos b√°sicos de la computaci√≥n paralela </a></li></h4>
				<h4 align= "Left "><li> <a href = "#4.2 Tipos de computaci√≥n paralela">4.2 Tipos de computaci√≥n paralela</a></li></h4>
				<h4 align= "Left "><li> <a href = "#4.3 Sistemas de memoria en multiprocesadores">4.3 Sistemas de memoria en multiprocesadores (Compartidas)</a></li></h4>
				<h4 align= "Left "><li> <a href = "#4.4 Sistemas de memoria en multiprocesadores (Distribuida)">4.4 Sistemas de memoria en multiprocesadores (Distribuida)</a></li></h4>
				<h4 align= "Left "><li> <a href = "#4.5 Casos para estudio">4.5 Casos para estudio</a></li></h4>
				<br> </br>
				<hr>
		<h2 style="color:blue; text-align:center; font-family:Book Antiqua"><a name= "4.1 Aspectos b√°sicos de la computaci√≥n paralela"> Aspectos b√°sicos de la computaci√≥n paralela</a></h2>
		<h3 style="text-decoration:underline;font-family:Comic Sans MS;color:#00BAC3; text-align: justify">4.1 Aspectos b√°sicos de la computaci√≥n paralela</h3>
		<p style="text-align:justify ; font-style:Book Antiqua; font-family:Arial">La computaci√≥n paralela es una forma de c√≥mputo en la que muchas instrucciones se ejecutan simult√°neamente, operando sobre el
			principio de que problemas grandes, a menudo se pueden dividir en unos m√°s peque√±os, que luego son resueltos simult√°neamente (en paralelo). Hay varias formas diferentes de computaci√≥n paralela:
			paralelismo a nivel de bit, paralelismo a nivel de instrucci√≥n, paralelismo de datos y paralelismo de tareas. El paralelismo se ha empleado durante muchos a√±os, sobre todo en la computaci√≥n de
			altas prestaciones, pero el inter√©s en ella ha crecido √∫ltimamente debido a las limitaciones f√≠sicas que impiden el aumento de la frecuencia. Como el consumo de energ√≠a y por consiguiente la
			generaci√≥n de calor de las computadoras constituye una preocupaci√≥n en los √∫ltimos a√±os, la computaci√≥n en paralelo se ha convertido en el paradigma dominante en la arquitectura de
			computadores, principalmente en forma de procesadores multin√∫cleo.</p>
			<center><div style="width:100%"> <img src = "IMAGENES/proP.jpg" style="height:250px; width:400px; float:center/rightwards; padding:10; margin:10"> </div></center>
			<br></br>
			<p style= "text-align: justify">Las computadoras paralelas pueden clasificarse seg√∫n el nivel de paralelismo que admite su hardware: equipos con procesadores multin√∫cleo y multi-procesador que tienen m√∫ltiples elementos de procesamiento dentro de una sola m√°quina y los cl√∫steres, MPPS y grids que utilizan varios equipos para trabajar en la misma tarea. 
			Muchas veces, para acelerar la tareas espec√≠ficas, se utilizan arquitecturas especializadas de computaci√≥n en paralelo junto a procesadores tradicionales.<br></br>
				Los programas inform√°ticos paralelos son m√°s dif√≠ciles de escribir que los secuenciales, porque la concurrencia introduce nuevos tipos de errores de software, siendo las condiciones de carrera los m√°s comunes. La comunicaci√≥n y sincronizaci√≥n entre diferentes subtareas son algunos de los mayores obst√°culos para obtener un buen rendimiento del programa paralelo.
				La m√°xima aceleraci√≥n posible de un programa como resultado de la paralelizaci√≥n se conoce como la ley de Amdahl.</p>
				
				
				<!--4.2-->
				<hr>
		<h2 style="color:blue; text-align:center; font-family:Book Antiqua"><a name= "4.2 Tipos de computaci√≥n paralela"> Tipos de computaci√≥n paralela</a></h2>
		
		<h5 align="left"><li> <a href = "#4.2.1 Clasificaci√≥n"> 4.2.1 Clasificaci√≥n </a></li>
		<li> <a href = "#4.2.2 Arquitectura de computadoras secuenciales">4.2.2 Arquitectura de computadoras secuenciales</a></li>
		<li><a href= "#4.2.3 Organizaci√≥n de direcciones de memoria">4.2.3 Organizaci√≥n de direcciones de memoria</a></li></h5>
		<br></br>
		<hr>
		<a name="4.2 Tipos de computaci√≥n paralela"><h3 style="text-decoration:underline;font-family:Comic Sans MS;color:#00BAC3;">4.2 Tipos de computaci√≥n paralela</h3>
		<p style="text-align:justify; font-style:Book Antiqua; font-family:Arial"><b>Paralelismo a nivel de bit:</b><br></br>
		Desde el advenimiento de la integraci√≥n a gran escala (VLSI) como tecnolog√≠a de fabricaci√≥n de chips de computadora en la d√©cada de 1970 hasta alrededor de 1986, la aceleraci√≥n en la arquitectura de computadores se lograba en gran medida duplicando el tama√±o de la palabra en la computadora, la cantidad de informaci√≥n que el procesador puede manejar por ciclo. <br></br>
		El aumento del tama√±o de la palabra reduce el n√∫mero de instrucciones que el procesador debe ejecutar para realizar una operaci√≥n en variables cuyos tama√±os son mayores que la longitud de la palabra. Por ejemplo, cuando un procesador de 8 bits debe sumar dos enteros de 16 bits, el procesador primero debe adicionar los 8 bits de orden inferior de cada n√∫mero entero con la instrucci√≥n de adici√≥n, 
		a continuaci√≥n, a√±adir los 8 bits de orden superior utilizando la instrucci√≥n de adici√≥n con acarreo que tiene en cuenta el bit de acarreo de la adici√≥n de orden inferior, en este caso un procesador de 8 bits requiere dos instrucciones para completar una sola operaci√≥n, en donde un procesador de 16 bits necesita una sola instrucci√≥n para poder completarla.<br></br>
		Hist√≥ricamente, los microprocesadores de 4 bits fueron sustituidos por unos de 8 bits, luego de 16 bits y 32 bits, esta tendencia general lleg√≥ a su fin con la introducci√≥n de procesadores de 64 bits, lo que ha sido un est√°ndar en la computaci√≥n de prop√≥sito general durante la √∫ltima d√©cada.</p>
		<center><div style="width:100%"> <img src = "IMAGENES/BIT.png" style="height:200px; width:550px; float:center/rightwards; padding:10; margin:10"> </div></center>
			<br></br>
		<p><b>Paralelismo a nivel de instrucci√≥n:</b><br></br>
			Un programa de ordenador es, en esencia, una secuencia de instrucciones ejecutadas por un procesador. Estas instrucciones pueden reordenarse y combinarse en grupos que luego son ejecutadas en paralelo sin cambiar el resultado del programa. Esto se conoce como paralelismo a nivel de instrucci√≥n. Los avances en el paralelismo a nivel de instrucci√≥n dominaron la arquitectura de computadores desde mediados de 1980 hasta mediados de la d√©cada de 1990.<br></br>
			Los procesadores modernos tienen ''pipeline'' de instrucciones de varias etapas. Cada etapa en el pipeline corresponde a una acci√≥n diferente que el procesador realiza en la instrucci√≥n correspondiente a la etapa; un procesador con un pipelinede N etapas puede tener hasta n instrucciones diferentes en diferentes etapas de finalizaci√≥n. El ejemplo can√≥nico de un procesador segmentado es un procesador RISC, con cinco etapas: pedir instrucci√≥n, decodificar, ejecutar, acceso a la memoria y escritura. El procesador Pentium 4 ten√≠a un pipeline de 35 etapas.<br></br>
			Adem√°s del paralelismo a nivel de instrucci√≥n del pipelining, algunos procesadores pueden ejecutar m√°s de una instrucci√≥n a la vez. Estos son conocidos como procesadores superescalares. Las instrucciones pueden agruparse juntas s√≥lo si no hay dependencia de datos entre ellas. El scoreboarding y el algoritmo de Tomasulo ‚Äîque es similar a scoreboarding pero hace uso del renombre de registros‚Äî son dos de las t√©cnicas m√°s comunes para implementar la ejecuci√≥n fuera de orden y la paralelizaci√≥n a nivel de instrucci√≥n.</p>
		<center><div style="width:100%"> <img src = "IMAGENES/INSTRUCCION.png" style="height:250px; width:600px; float:center/rightwards; padding:10; margin:10"> </div></center>
			<br></br>
			<p>Adem√°s del paralelismo a nivel de instrucci√≥n del pipelining, algunos procesadores pueden ejecutar m√°s de una instrucci√≥n a la vez. Estos son conocidos como procesadores superescalares. Las
			instrucciones pueden agruparse juntas s√≥lo si no hay dependencia de datos entre ellas. El scoreboarding y el algoritmo de Tomasulo ‚Äî que es similar a scoreboarding pero hace uso del renombre de
			registros‚Äî son dos de las t√©cnicas m√°s comunes para implementar la ejecuci√≥n fuera de orden y la paralelizaci√≥n a nivel de instrucci√≥n.</p>
		 <p><b>El paralelismo de datos:</b><br></br> Es el paralelismo inherente en programas con ciclos, que se centra en la distribuci√≥n de los datos entre los
				diferentes nodos computacionales que deben tratarse en paralelo. "La paralelizaci√≥n de ciclos conduce a menudo a secuencias similares de operaciones ‚Äîno necesariamente id√©nticas‚Äî o funciones que se realizan en los elementos de una gran estructura de
				datos". Muchas de las aplicaciones cient√≠ficas y de ingenier√≠a muestran paralelismo de datos.<br></br>
				Una dependencia de terminaci√≥n de ciclo es la dependencia de una iteraci√≥n de un ciclo en la salida de una o m√°s iteraciones anteriores.
				Las dependencias de terminaci√≥n de ciclo evitan la paralelizaci√≥n de ciclos.</p>
				<Center><div style="width:100%"> <img src = "IMAGENES/datos.png" style="height:250px; width:600px; float:center/rightwards; padding:10; margin:10"> </div></center>
			<br></br>
		<p><b>Paralelismo de tareas:</b><br></br>
			Paralelismo de tareas es un paradigma de la programaci√≥n concurrente que consiste en asignar distintas tareas a cada uno de los procesadores de un sistema de c√≥mputo. En consecuencia, cada
			procesador efectuar√° su propia secuencia de operaciones. En su modo m√°s general, el paralelismo de tareas se representa mediante un grafo de tareas, el cual es subdividido en subgrafos que
			son luego asignados a diferentes procesadores. De la forma como se corte el grafo, depende la eficiencia de paralelismo resultante. La partici√≥n y asignaci√≥n √≥ptima de un grafo de tareas para ejecuci√≥n
			concurrente es un problema NP-completo, por lo cual en la pr√°ctica se dispone de m√©todos heur√≠sticos aproximados para lograr una asignaci√≥n cercana a la √≥ptima.<br></br>

			Sin embargo, existen ejemplos de paralelismo de tareas restringido que son de inter√©s en programaci√≥n concurrente. Tal es el caso del paralelismo encauzado, en el cual el grafo tiene forma de cadena,
			donde cada nodo recibe datos del nodo previo y sus resultados son enviados al nodo siguiente. El car√°cter simplificado de este modelo permite obtener paralelismo de eficiencia √≥ptima.</p>
		<center><div style="width:100%"> <img src = "IMAGENES/tareas.jpg" style="height:250px; width:400px; float:center/rightwards; padding:10; margin:10"> </div></center>
			<br></br>
		<hr>
		<h2 style="color:blue; text-align:center; font-family:Book Antiqua"><a name= "4.2.1 Clasificaci√≥n">Clasificaci√≥n</a></h2>
		<a name="4.2.1 Clasificaci√≥n"><h3 style="text-decoration:underline;font-family:Comic Sans MS;color:#00BAC3;">4.2.1 Clasificaci√≥n</h3>
		<p style="text-align:justify; font-style:Book Antiqua; font-family:Arial">Las computadoras paralelas se pueden clasificar de acuerdo con el nivel en el que el hardware soporta paralelismo. Esta clasificaci√≥n es
				an√°loga a la distancia entre los nodos b√°sicos de c√≥mputo. Estos no son excluyentes entre s√≠, por ejemplo, los grupos de multiprocesadores sim√©tricos son relativamente comunes.<br></br>
				‚Ä¢ Computaci√≥n multin√∫cleo: un procesador multin√∫cleo es un procesador que incluye m√∫ltiples unidades de ejecuci√≥n
				(n√∫cleos) en el mismo chip. Un procesador multin√∫cleo puede ejecutar m√∫ltiples instrucciones por ciclo de secuencias de instrucciones m√∫ltiples.<br></br>
				‚Ä¢ Multiprocesamiento sim√©trico: un multiprocesador sim√©trico (SMP) es un sistema computacional con m√∫ltiples
				procesadores id√©nticos que comparten memoria y se conectan a trav√©s de un bus. La contenci√≥n del bus previene el escalado de esta arquitectura.<br></br>
				‚Ä¢ Computaci√≥n en cl√∫ster: un cl√∫ster es un grupo de ordenadores d√©bilmente acoplados que trabajan en estrecha
				colaboraci√≥n, de modo que en algunos aspectos pueden considerarse como un solo equipo.<br></br>
				‚Ä¢ Procesamiento paralelo masivo: tienden a ser m√°s grandes que los cl√∫steres, con ¬´mucho m√°s¬ª de 100 procesadores. En
				un MPP, cada CPU tiene su propia memoria y una copia del sistema operativo y la aplicaci√≥n.<br></br>
				‚Ä¢ Computaci√≥n distribuida: la computaci√≥n distribuida es la forma m√°s distribuida de la computaci√≥n paralela. Se hace uso
				de ordenadores que se comunican a trav√©s de la Internet para trabajar en un problema dado.<br></br>
				‚Ä¢ Computadoras paralelas especializadas: dentro de la computaci√≥n paralela, existen dispositivos paralelos especializados que generan inter√©s. Aunque no son espec√≠ficos
				para un dominio, tienden a ser aplicables s√≥lo a unas pocas clases de problemas paralelos.<br></br>
				‚Ä¢ C√≥mputo reconfigurable con arreglos de compuertas programables: el c√≥mputo reconfigurable es el uso de un
				arreglo de compuertas programables (FPGA) como coprocesador de un ordenador de prop√≥sito general.<br></br>
				‚Ä¢ C√≥mputo de prop√≥sito general en unidades de procesamiento gr√°fico (GPGPU): es una tendencia relativamente reciente en la investigaci√≥n de ingenier√≠a
				inform√°tica. Los GPUs son co-procesadores que han sido fuertemente optimizados para procesamiento de gr√°ficos por computadora.<br></br>
				‚Ä¢ Circuitos integrados de aplicaci√≥n espec√≠fica: debido a que un ASIC (por definici√≥n) es espec√≠fico para una aplicaci√≥n dada, puede ser completamente optimizado para esa
				aplicaci√≥n. Como resultado, para una aplicaci√≥n dada, un ASIC tiende a superar a un ordenador de prop√≥sito general.<br></br>
				‚Ä¢ Procesadores vectoriales: pueden ejecutar la misma instrucci√≥n en grandes conjuntos de datos. Tienen operaciones
				de alto nivel que trabajan sobre arreglos lineales de n√∫meros o vectores.</p>
				<br></br>
		<hr>
		<h2 style="color:blue; text-align:center; font-family:Book Antiqua"><a name= "4.2.2 Arquitectura de computadoras secuenciales"> Arquitectura de computadoras secuenciales </h2>
		<h3 style="text-decoration:underline;font-family:Comic Sans MS;color:#00BAC3;">4.2.2 Arquitectura de computadoras secuenciales</h3>
		<p style="text-align:justify; font-style:Book Antiqua; font-family:Arial">A diferencia de los sistemas combinacionales, en los sistemas
			secuenciales, los valores de las salidas, en un momento dado, no dependen exclusivamente de los valores de las entradas en dicho
			momento, sino tambi√©n dependen del estado anterior o estado interno. El sistema secuencial m√°s simple es el biestable, de los cuales, el de tipo D (o cerrojo) es el m√°s utilizado actualmente.<br></br>
			El sistema secuencial requiere de la utilizaci√≥n de un dispositivo de memoria que pueda almacenar la historia pasada de sus entradas (denominadas variables de estado) y le permita mantener su estado
			durante alg√∫n tiempo, estos dispositivos de memoria pueden ser sencillos como un simple retardador o celdas de memoria de tipo
			DRAM, SRAM o multivibradores biestables tambi√©n conocido como Flip-Flop.<br></br>
			<b>Tipos de sistemas secuenciales</b><br></br>
			En este tipo de circuitos entra un factor que no se hab√≠a considerado en los circuitos combinacionales, dicho factor es el tiempo, seg√∫n
			como manejan el tiempo se pueden clasificar en: circuitos secuenciales s√≠ncronos y circuitos secuenciales as√≠ncronos.<br></br>

			<b>Circuitos secuenciales as√≠ncronos.</b><br></br>
			En circuitos secuenciales as√≠ncronos los cambios de estados ocurren al ritmo natural asociado a las compuertas l√≥gicas utilizadas en su
			implementaci√≥n, lo que produce retardos en cascadas entre los biestables del circuito, es decir no utilizan elementos especiales de
			memoria, lo que puede ocasionar algunos problemas de funcionamiento, ya que estos retardos naturales no est√°n bajo el
			control del dise√±ador y adem√°s no son id√©nticos en cada compuerta l√≥gica.<br></br>
			<b>Circuitos secuenciales s√≠ncronos.</b><br></br>
			Los circuitos secuenciales s√≠ncronos solo permiten un cambio de
			estado en los instantes marcados o autorizados por una se√±al de
			sincronismo de tipo oscilatorio denominada reloj (cristal o circuito
			capaz de producir una serie de pulsos regulares en el tiempo), lo que
			soluciona los problemas que tienen los circuitos as√≠ncronos
			originados por cambios de estado no uniformes dentro del sistema o
			circuito.</p>
			<center><div style="width:100%"> <img src = "IMAGENES/secuenciales.png" style="height:190px; width:460px; float:center-left; padding:10; margin:10"> </div></center>
		<br></br>
		<hr>
		<h2 style="color:blue; text-align:center; font-family:Book Antiqua"><a name="4.2.3 Organizaci√≥n de direcciones de memoria">Organizaci√≥n de direcciones de memoria</h2>
		<h3 style="text-decoration:underline;font-family:Comic Sans MS;color:#00BAC3;">4.2.3 Organizaci√≥n de direcciones de memoria</h3>
		<p style="text-align:justify; font-style:Book Antiqua; font-family:Arial">La memoria principal en un ordenador en paralelo puede ser
				compartida ‚Äîcompartida entre todos los elementos de
				procesamiento en un √∫nico espacio de direcciones‚Äî, o distribuida
				‚Äîcada elemento de procesamiento tiene su propio espacio local de
				direcciones‚Äî. El t√©rmino memoria distribuida se refiere al hecho de
				que la memoria se distribuye l√≥gicamente, pero a menudo implica que tambi√©n se distribuyen f√≠sicamente. La memoria distribuida-
				compartida y la virtualizaci√≥n de memoria combinan los dos enfoques, donde el procesador tiene su propia memoria local y
				permite acceso a la memoria de los procesadores que no son locales.
				Los accesos a la memoria local suelen ser m√°s r√°pidos que los
				accesos a memoria no local.<br></br>

				Las arquitecturas de ordenador en las que cada elemento de la
				memoria principal se puede acceder con igual latencia y ancho de
				banda son conocidas como arquitecturas de acceso uniforme a
				memoria (UMA). T√≠picamente, s√≥lo se puede lograr con un sistema
				de memoria compartida, donde la memoria no est√° distribuida
				f√≠sicamente. Un sistema que no tiene esta propiedad se conoce como
				arquitectura de acceso a memoria no uniforme (NUMA). Los
				sistemas de memoria distribuidos tienen acceso no uniforme a la
				memoria.</p>
				<center><div style="width:100%"> <img src = "IMAGENES/direcciones.png" style="height:290px; width:460px; float:center-left; padding:10; margin:10"> </div></center>
		<br></br>
		<!--4.3-->
				<hr>
		<h2 style="color:blue; text-align:center; font-family:Book Antiqua"><a name= "4.3 Sistemas de memoria en multiprocesadores">Sistemas de memoria en multiprocesadores(Compartidas)</a></h2>
		
		<h6 align="left"><li> <a href = "#4.3.1 Redes de interconexi√≥n dinamica"> 4.3.1 Redes de interconexi√≥n dinamica</a></li><h/6>
		<li> <a href = "#4.3.2 Medio compartido">4.3.2 Medio compartido</a></li>
		<li><a href= "#4.3.3 Conmutados">4.3.3 Conmutados</a></li>
		<hr>
		<a name="4.2 Tipos de computaci√≥n paralela"><h3 style="text-decoration:underline;font-family:Comic Sans MS;color:#00BAC3;">4.3 Sistemas de memoria en multiprocesadores(Compartidas)</h3>
		<p style="text-align:justify; font-style:Book Antiqua; font-family:Arial">Un multiprocesador puede verse como un computador paralelo compuesto por varios procesadores interconectados que comparten un mismo sistema de memoria. <br></br>
		Los sistemas multiprocesadores son arquitecturas MIMD con memoria compartida. Tienen un √∫nico espacio de direcciones para todos los procesadores 
		y los mecanismos de comunicaci√≥n se basan en el paso de mensajes desde el punto de vista del programador.<br></br>
		Todos los procesadores acceden a una memoria com√∫n.<br></br>
		‚óê‚úì La comunicaci√≥n entre procesadores se hace a trav√©s de la memoria.<br></br>
		‚óê‚úì Se necesitan primitivas de sincronismo para asegurar el intercambio de datos.<br></br>
		<center><div style="width:100%"> <img src = "IMAGENES/MemoriaCompartida.jpg" style="height:331px; width:420px; float:center-left; padding:10; margin:10"> </div></center>
		<br></br>
		<p style= "text-align: Center"><b>Estructura de los multiprocesadores de memoria compartida.</b></p>
			<p>La mayor√≠a de los multiprocesadores comerciales son del tipo UMA (Uniform Memory Access): todos los procesadores tienen igual
				tiempo de acceso a la memoria compartida. En la arquitectura UMA los procesadores se conectan a la memoria a trav√©s de un bus, una
				red multietapa o un conmutador de barras cruzadas (red multietapa o un conmutador de barras cruzadas (crossbar crossbar) y disponen de
				su propia ) y disponen de su propia memoria cach√©. Los procesadores tipo NUMA (Non Uniform Memory Access) presentan
				tiempos de acceso a la memoria compartida que dependen de la ubicaci√≥n del elemento de proceso y la memoria.</p>
				<center><div style="width:100%"> <img src = "IMAGENES/UMA.png" style="height:442px; width:948px; float:center-left; padding:10; margin:10"> </div></center>
		<br></br>
		<hr>
		<h2 style="color:blue; text-align:center; font-family:Book Antiqua"><a name= "4.3.1 Redes de interconexi√≥n dinamica">Redes de interconexi√≥n dinamica</a></h2>
		<h3 style="text-decoration:underline;font-family:Comic Sans MS;color:#00BAC3;">4.3.1 Redes de interconexi√≥n dinamica</h3>
		<p style="text-align:justify; font-style:Book Antiqua; font-family:Arial">Uno de los criterios m√°s importantes para la clasificaci√≥n de las redes es el que tiene en cuenta la situaci√≥n de la red en la m√°quina paralela, dando lugar a dos familias de redes: redes est√°ticas y redes din√°micas. 
		Una red est√°tica es una red cuya topolog√≠a queda definida de manera definitiva y estable durante la construcci√≥n de la m√°quina paralela.
		<br></br>La red simplemente une los diversos elementos de acuerdo a una configuraci√≥n dada. Se utiliza sobre todo en el caso de los multicomputadores para conectar los diversos procesadores que posee la m√°quina. Por la red s√≥lo circulan los mensajes entre procesadores, por lo que se dice que la red presenta un acoplamiento d√©bil. 
		En general, en las redes est√°ticas se exige poca carga a la red. 
		<br></br>Una red din√°mica es una red cuya topolog√≠a puede variar durante el curso de la ejecuci√≥n de un programa paralelo o entre dos ejecuciones de programas. La red est√° constituida por elementos materiales espec√≠ficos, llamados commutadores o switches.
		<br></br>Las redes din√°micas se utilizan sobre todo en los multiprocesadores. En este caso, la red une los procesadores a los bancos de memoria central. Cualquier acceso de un procesador a la memoria (bien sea para acceder a los datos o a las instrucciones) debe pasar a trav√©s de la red, por lo se dice que la red tiene un acoplamiento fuerte. 
		La red debe poseer un rendimiento extremadamente bueno para no demorar demasiado a los procesadores que acceden a memoria.
			<center><div style="width:100%"> <img src = "IMAGENES/dinamicas.png" style="height:442px; width:648px; float:center-left; padding:10; margin:10"> </div></center>
		<br></br>
				<hr>
		<h2 style="color:blue; text-align:center; font-family:Book Antiqua"><a name= "4.3.2 Medio compartido">Medio compartido</a></h2>
		<h3 style="text-decoration:underline;font-family:Comic Sans MS;color:#00BAC3;">4.3.2 Medio compartido</h3>
		<br></br>
		<p style="text-align:justify; font-style:Book Antiqua; font-family:Arial"><b>1- Conexi√≥n por bus compartido.</b>
			Es la organizaci√≥n m√°s com√∫n en los computadores personales y
			servidores.<br></br>
			El bus consta de l√≠neas de direcci√≥n, datos y control para implementar:<br></br>
					&nbsp; &nbsp; &nbsp;‚öúÔ∏è El protocolo de transferencias de datos con la memoria.<br></br>
					&nbsp; &nbsp; &nbsp;‚öúÔ∏è Ô∏èEl arbitraje del acceso al bus cuando m√°s de un procesador
			compite por utilizarlo.<br></br>
			Los procesadores utilizan cach√©s locales para:<br></br>
					&nbsp; &nbsp; &nbsp;‚öúÔ∏è Reducir el tiempo medio de acceso a memoria, como en un monoprocesador.<Br></br>
					&nbsp; &nbsp; &nbsp;‚öúÔ∏è Disminuir la utilizaci√≥n del bus compartido.</p>
		<center><div style="width:100%"> <img src = "IMAGENES/busCompartido.png" style="height:306px; width:476px; float:center-left; padding:10; margin:10"> </div></center>
		<br></br>
		<p><b>2- Protocolos de transferencia de ciclo partido.</b><br></br>
			La operaci√≥n de lectura se divide en dos transacciones no continuas de acceso al bus. La primera es de petici√≥n de lectura que realiza el m√°ster (procesador) sobre el slave (memoria). Una vez realizada la
			petici√≥n el m√°ster abandona el bus. Cuando el slave dispone del dato le√≠do, inicia un ciclo de bus actuando como m√°ster para enviar el dato al antiguo m√°ster, que ahora act√∫a como slave.</p>
			<center><div style="width:100%"> <img src = "IMAGENES/CICLOPARTIDO.png" style="height:306px; width:576px; float:center-left; padding:10; margin:10"> </div></center>
		<br></br>
		<p><b>3- Protocolo de arbitraje distribuido</b><br></br>
		La responsabilidad del arbitraje se distribuye por los diferentes procesadores conectados al bus.<br></br>
		<center><div style="width:100%"> <img src = "IMAGENES/CICLOPARTIDO.png" style="height:306px; width:576px; float:center-left; padding:10; margin:10"> </div></center>
		<br></br>
		Arbitro-i concede el bus al procesador Pi activando Gi si:<br></br>
				&nbsp; &nbsp; &nbsp; 1. Pi ha activado su l√≠nea de petici√≥n de bus Ri.<br></br>
				&nbsp; &nbsp; &nbsp; 2. La l√≠nea de ocupaci√≥n est√° desactivada.<br></br>
				&nbsp; &nbsp; &nbsp; 3. La l√≠nea de entrada de prioridad pi-1 est√° activada.<br></br>
				El √°rbitro i activa su l√≠nea de prioridad pi si:<br></br>
				&nbsp; &nbsp; &nbsp; 1. Pi no ha activado su l√≠nea de petici√≥n Ri.<br></br>
				&nbsp; &nbsp; &nbsp; 2. La l√≠nea de prioridad pi-1 est√° activa.<br></br>
				&nbsp; &nbsp; &nbsp; 3. Finaliza una operaci√≥n de acceso al bus.
		</p>	
		<!--4.3.3-->
				<hr>
		<h2 style="color:blue; text-align:center; font-family:Book Antiqua"><a name= "4.3.3 Conmutados">Conmutadas</a></h2>
		<h3 style="text-decoration:underline;font-family:Comic Sans MS;color:#00BAC3;">4.3.3 Conmutadas</h3>
		<p style="text-align:justify; font-style:Book Antiqua; font-family:Arial"><b>1- Conexi√≥n por conmutadores crossbar.</b><br></br>
		Cada procesador (Pi) y cada m√≥dulo de memoria (Mi) tienen su propio bus. Existe un conmutador (S) en los puntos de intersecci√≥n que permite conectar un bus de memoria con un bus de procesador.
		Para evitar conflictos cuando m√°s de un procesador pretende acceder al mismo m√≥dulo de memoria se establece un orden de prioridad. Se
		trata de una red sin bloqueo con una conectividad completa pero de alta complejidad.</p>
		<center><div style="width:100%"> <img src = "IMAGENES/conexion.png" style="height:214px; width:490px; float:center-left; padding:10; margin:10"> </div></center>
		<br></br>
		<p><b>2- Conexi√≥n por red multietapa.</b><br></br>
			üòé Representan una alternativa intermedia de conexi√≥n entre el bus y el crossbar.<br></br>
			üòé Es de menor complejidad que el crossbar pero mayor que el bus simple.<br></br>
			üòé La conectividad es mayor que la del bus simple pero menor que la del crossbar.<br></br>
			üòé Se compone de varias etapas alternativas de conmutadores simples y redes de interconexi√≥n.</p>
			<center><div style="width:100%"> <img src = "IMAGENES/multietapa.png" style="height:214px; width:490px; float:center-left; padding:10; margin:10"> </div></center>
		<br></br>
			<!--4.4-->
				<hr>
		<h2 style="color:blue; text-align:center; font-family:Book Antiqua"><a name= "4.4 Sistemas de memoria en multiprocesadores (Distribuida)">Sistemas de memoria en multiprocesadores (Distribuida)</a></h2>
		
		<h6 align="left"><li> <a href = "#4.4.1 Redes de interconexi√≥n estatica"> 4.4.1 Redes de interconexi√≥n estatica</a></li><h/6>
		<hr>
		<a name="4.4 Sistemas de memoria en multiprocesadores (Distribuida)"><h3 style="text-decoration:underline;font-family:Comic Sans MS;color:#00BAC3;">4.4 Sistemas de memoria en multiprocesadores (Distribuida)</h3>
		<br></br>
		<p style="text-align:justify; font-style:Book Antiqua; font-family:Arial">Cada procesador tiene su propia memoria y la comunicaci√≥n se realiza por intercambio expl√≠cito de mensajes a trav√©s de una red.</p>
		<p><b>Ventajas</b><br></br>
				&nbsp; &nbsp; &nbsp; üî∏ El n√∫mero de nodos puede ir desde algunas decenas hasta varios miles (o m√°s).<br></br>
				&nbsp; &nbsp; &nbsp; üî∏ La arquitectura de paso de mensajes tiene ventajas sobre la de memoria compartida cuando el n√∫mero de procesadores es grande.<br></br>
				&nbsp; &nbsp; &nbsp; üî∏ El n√∫mero de canales f√≠sicos entre nodos suele oscilar entre cuatro y ocho.<br></br>
				&nbsp; &nbsp; &nbsp; üî∏ Esta arquitectura es directamente escalable y presenta un bajo coste para sistemas grandes.<br></br>
				&nbsp; &nbsp; &nbsp; üî∏ Un problema se especifica como un conjunto de procesos que se comunican entre s√≠ y que se hacen corresponder sobre la estructura f√≠sica de procesadores.<br></br>
				<b>Desventajas</b><br></br>
				&nbsp; &nbsp; &nbsp; üî∏ Se necesitan t√©cnicas de sincronizaci√≥n para acceder a las variables compartidas.<br></br>
				&nbsp; &nbsp; &nbsp; üî∏ La contenci√≥n en la memoria puede reducir significativamente la velocidad.<br></br>
				&nbsp; &nbsp; &nbsp; üî∏ No son f√°cilmente escalables a un gran n√∫mero de procesadores.</p>
				<center><div style="width:100%"> <img src = "IMAGENES/distribuida.png" style="height:391px; width:339px; float:center; padding:10; margin:10"> </div></center>
		<br></br>
		<!--4.4.1-->
				<hr>
		<h2 style="color:blue; text-align:center; font-family:Book Antiqua"><a name= "4.4.1 Redes de interconexi√≥n estatica">Redes de interconexi√≥n estatica</a></h2>
		<h3 style="text-decoration:underline;font-family:Comic Sans MS;color:#00BAC3;">4.4.1 Redes de interconexi√≥n estatica</h3>
		<p style="text-align:justify; font-style:Book Antiqua; font-family:Arial">Los multicomputadores utilizan redes est√°ticas con enlaces directos entre nodos. 
			Cuando un nodo recibe un mensaje lo procesa si viene dirigido a dicho nodo. Si el mensaje no va dirigido al nodo receptor lo reenv√≠a a otro por alguno de sus enlaces de salida siguiendo un protocolo de encaminamiento.<br></br>
			<b>Propiedades m√°s significativas</b><Br></br>
					&nbsp; &nbsp; &nbsp; ‚ñ™Ô∏è Topolog√≠a de la red: determina el patr√≥n de interconexi√≥n entre nodos.<br></br>
					&nbsp; &nbsp; &nbsp; ‚ñ™Ô∏è Di√°metro de la red: distancia m√°xima de los caminos m√°s cortos entre dos nodos de la red.<br></br>
					&nbsp; &nbsp; &nbsp; ‚ñ™Ô∏è Latencia: retardo de tiempo en el peor caso para un mensaje transferido a trav√©s de la red.<br></br>
					&nbsp; &nbsp; &nbsp; ‚ñ™Ô∏è Ancho de banda: Transferencia m√°xima de datos en Mbytes/segundo.<br></br>
					&nbsp; &nbsp; &nbsp; ‚ñ™Ô∏è Escalabilidad: posibilidad de expansi√≥n modular de la red.<br></br>
					&nbsp; &nbsp; &nbsp; ‚ñ™Ô∏è Grado de un nodo: n√∫mero de enlaces o canales que inciden en el nodo.<br></br>
					&nbsp; &nbsp; &nbsp; ‚ñ™Ô∏è Algoritmo de encaminamiento: determina el camino que debe seguir un mensaje desde el nodo emisor al nodo receptor.<br></br>
					<center><div style="width:100%"> <img src = "IMAGENES/estatica.png" style="height:225px; width:115x; float:center; padding:10; margin:10"> </div></center>
		<br></br>
		<!--4.5-->
				<hr>
		<h2 style="color:blue; text-align:center; font-family:Book Antiqua"><a name= "4.5 Casos para estudio">Casos para estudio</a></h2>
		<h3 style="text-decoration:underline;font-family:Comic Sans MS;color:#00BAC3;">4.5 Casos para estudio</h3>
		<p style="text-align:justify; font-style:Book Antiqua; font-family:Arial"> Por numerosos motivos, el procesamiento distribuido se ha
					convertido en un √°rea de gran importancia e inter√©s dentro de la ciencia de la computaci√≥n, produciendo profundas transformaciones en las l√≠neas de investigaci√≥n y desarrollo.<br></br>
				Interesa realizar investigaci√≥n en la especificaci√≥n, transformaci√≥n, optimizaci√≥n y evaluaci√≥n de algoritmos distribuidos y paralelos.
				Esto incluye el dise√±o y desarrollo de sistemas paralelos, la transformaci√≥n de algoritmos secuenciales en paralelos, y las
				m√©tricas de evaluaci√≥n de performance sobre distintas plataformas de soporte (hardware y software). M√°s all√° de las mejoras constantes
				en las arquitecturas f√≠sicas de soporte, uno de los mayores desaf√≠os se centra en c√≥mo aprovechar al m√°ximo la potencia de las mismas.</p>

				<p style= "text-align: center"><b>L√≠neas de investigaci√≥n y desarrollo</p></b><br></br>
				<p style="text-align:justify; font-style:Book Antiqua; font-family:Arial">
					&nbsp; &nbsp; &nbsp; ‚≠ê Paralelizaci√≥n de algoritmos secuenciales. Dise√±o y optimizaci√≥n de algoritmos.<br></br>
					&nbsp; &nbsp; &nbsp; ‚≠ê Arquitecturas multicore y multithreading en multicore.<br></br>
					&nbsp; &nbsp; &nbsp; ‚≠ê Modelos de representaci√≥n y predicci√≥n de performance de algoritmos paralelos.<br></br>
					&nbsp; &nbsp; &nbsp; ‚≠ê Mapping y scheduling de aplicaciones paralelas sobre distintas arquitecturas multiprocesador.<br></br>
					&nbsp; &nbsp; &nbsp; ‚≠ê M√©tricas del paralelismo. Speedup, eficiencia, rendimiento, granularidad, superlinealidad.<br></br>
					&nbsp; &nbsp; &nbsp; ‚≠ê Balance de carga est√°tico y din√°mico. T√©cnicas de balanceo de carga.<br></br>
					&nbsp; &nbsp; &nbsp; ‚≠ê An√°lisis de los problemas de migraci√≥n y asignaci√≥n √≥ptima de procesos y datos a procesadores.<br></br>
					&nbsp; &nbsp; &nbsp; ‚≠ê Patrones de dise√±o de algoritmos paralelos.<br></br>
					&nbsp; &nbsp; &nbsp; ‚≠ê Escalabilidad de algoritmos paralelos en arquitecturas multiprocesador distribuidas.<br></br>
					&nbsp; &nbsp; &nbsp; ‚≠ê Implementaci√≥n de soluciones sobre diferentes modelos de arquitectura homog√©neas y heterog√©neas.<br></br>
					&nbsp; &nbsp; &nbsp; ‚≠ê Laboratorios remotos para el acceso transparente a recursos de c√≥mputo paralelo.<br></br>

					<b>Algunas Implementaciones con procesamiento paralelo.</b><br></br>
					1- NVIDIA
					Capa f√≠sica (physical layer):<br></br>
					&nbsp; &nbsp; &nbsp; üß© GPU PhysX.<br></br>
					&nbsp; &nbsp; &nbsp; üß© CPU PhysX.<br></br>
					 Capa de gr√°ficos (graphics layer):<br></br>
					&nbsp; &nbsp; &nbsp;üß© GPU DirectX Windows.<br></br>
					2- Intel<br></br>
					Capa f√≠sica (physical layer):<br></br>
					&nbsp; &nbsp; &nbsp;üß© No GPU PhysX.<br></br>
					&nbsp; &nbsp; &nbsp;üß© CPU Havok.<br></br>
					Capa de gr√°ficos (graphics layer):<br></br>
					&nbsp; &nbsp; &nbsp;üß© GPU DirectX Windows.<br></br>
					3- AMD
					Capa f√≠sica (physical layer):<br></br>
					&nbsp; &nbsp; &nbsp;üß© No GPU PhysX.<br></br>
					&nbsp; &nbsp; &nbsp;üß© CPU Havok.<br></br>
					Capa de gr√°ficos (graphics layer):<br></br>
					&nbsp; &nbsp; &nbsp;üß© GPU DirectX Windows.
</p>
</html>